# Install packages
install.packages("ggplot2")
library(ggplot2)
install.packages("psych")
library(psych)
install.packages("dplyr")
library(dplyr)
install.packages("moments")
library(moments)
install.packages("dplyr")
# Check working directory/change working directory
getwd()
setwd("C:/Users/admin/factor_analysis/BIG5/BIG5")
# Import data
data = read.csv("data.csv",header = TRUE,sep = "")
View(data)
# Descriptive Statistics - Exploratory Data Analysis
str(data)
# Replace race column with the corresponding values
data$race[data$race == 0] = "Other (0=missed)"
data$race[data$race == 1] = "Mixed Race"
data$race[data$race == 2] = "Arctic (Siberian, Eskimo)"
data$race[data$race == 3] = "Caucasian (European)"
data$race[data$race == 4] = "Caucasian (Indian)"
data$race[data$race == 5] = "Caucasian (Middle East)"
data$race[data$race == 6] = "Caucasian (North African, Other)"
data$race[data$race == 7] = "Indigenous Australian"
data$race[data$race == 8] = "Native American"
data$race[data$race == 9] = "North East Asian (Mongol, Tibetan, Korean Japanese, etc)"
data$race[data$race == 10] = "Pacific (Polynesian, Micronesian, etc)"
data$race[data$race == 11] = "South East Asian (Chinese, Thai, Malay, Filipino, etc)"
data$race[data$race == 12] = "West African, Bushmen, Ethiopian"
data$race[data$race == 13] = "Other (0=missed)"
# Replace engnat column, 1 == Yes, 2 == No
data$engnat = ifelse(data$engnat == 1, "Yes", "No")
# Replace gender column, 1 == Male, 2 == Female, 3 == Other
data$gender = ifelse(data$gender == 1, "Male",ifelse(data$gender == 2, "Female", "Other"))
# Replace hand column, 1 == Right, 2 == Left, 3 == Both
data$hand = ifelse(data$hand == 1, "Right", ifelse(data$hand == 2, "Left", "Both"))
# Drop NAs in demographic data
which(is.na(data)==TRUE)
data = na.omit(data)
# Age column : Remove ages above 100 years old
data = subset(data, data$age <= 100)
# Age Distribution
ggplot(data = data,mapping = aes(x = age))+
geom_histogram(colour = "blue",fill = "blue")+
ylab("Frequency")+ggtitle("Age Distribution")
# Age Distribution Statistics
summary(data$age)
# Age Skewness
skewness(data$age)
# Age by Gender
data %>% group_by(gender) %>% summarise(mean(age))
# Gender Barplot
ggplot(data = data, mapping = aes(x = gender))+
geom_bar(fill = c("lightpink","lightblue","red"))+
ylab("Frequency")+ggtitle("Gender Frequency")
# Gender Count
data %>% group_by(gender) %>% summarise(count = n())
# Hand Barplot
ggplot(data = data, mapping = aes(x = hand))+
geom_bar(fill = c("lightpink","lightblue","red"))+
ylab("Frequency")+ggtitle("Main Hand Frequency")
# Hand count
data %>% group_by(hand) %>% summarise(count = n())
# Race Frequencies
data %>% group_by(race) %>% summarise(n = n()) %>% arrange(desc(n))
# Country Frequencies
data %>% group_by(country) %>% summarise(n = n()) %>% arrange(desc(n))
# Split data into demografics (exclude source column) and questionaire
demo_data = subset(data, select = c("race","age","engnat","gender","hand","country"))
question_data = data %>% select(E1:O10)
# Step 1 : Check if the dataset is suitable for factor analysis
0.00001 < det(cov(question_data)) # Determinant of covariance matrix bigger than 0.00001
cortest.bartlett(question_data) # Bartlett Test of Sphericity - Reject Null Hypothesis
KMO(question_data) # MSA for each item bigger than 0.6 and overall MSA = 0.91
# Step 2 : Determine the number of factors
eigen_values = eigen(cor(question_data))$values
var_explained = cumsum(eigen_values)/sum(eigen_values)
scree(question_data) # 5
fa.parallel(question_data)
VSS(question_data) # 5 Î® 6
# Step 2 : Determine the number of factors
eigen_values = eigen(cor(question_data))$values
eigen_values
# Step 2 : Determine the number of factors
eigen_values = eigen(cov(question_data))$values
eigen_values
# Step 2 : Determine the number of factors
eigen_values = eigen(cor(question_data))$values
eigen_values
scree(question_data) # 5
scree(question_data,factors = TRUE) # 5
scree(question_data,factors = TRUE) # 5
scree(question_data,factors = TRUE,pc = FALSE) # 5
scree(question_data) # 5
scree(question_data,factors = FALSE) # 5
fa.parallel(question_data)
# Step 2 : Determine the number of factors
scree(question_data,factors = FALSE) # 5
# Step 2 : Determine the number of factors
scree(question_data,factors = TRUE, pc = FALSE) # 5
# Step 3 : Estimate Models Parameters
factor_model_fit = principal(question_data,nfactors = 5,rotate = "varimax",scores=TRUE)
factor_model_fit
print.psych(factor_model_fit,cut = 0.35, sort = TRUE)
# Step 3 : Estimate Models Parameters
factor_model_fit = principal(question_data,nfactors = 5,rotate = "varimax",scores=TRUE)
print.psych(factor_model_fit,cut = 0.35, sort = TRUE)
factor_model_fit$loadings
unname(factor_model_fit$loadings)
df = unname(factor_model_fit$loadings)
apply(df, 1, abs(max))
apply(abs(df), 1, max)
as.data.frame(apply(abs(df), 1, max))
df = unclass(factor_model_fit$loadings)
as.data.frame(apply(abs(df), 1, max))
df
remove_below_zerofour = function(x){
if (abs(x) <= 0.4){
x = ""
}
}
apply(df, 1, remove_below_zerofour)
return(x)
remove_below_zerofour = function(x){
if (abs(x) <= 0.4){
x = ""
return(x)
}
}
apply(df, 1, remove_below_zerofour)
remove_below_zerofour = function(x){
if (abs(x) <= 0.4){
x = ""
return(x)
} else {
return(x)
}
}
apply(df, 1, remove_below_zerofour)
remove_below_zerofour = function(x){
for (i in length(x)) {
if (x[i] <= 0.4) {
x[i] = ""
}
return(x)
}
}
remove_below_zerofour = function(x){
for (i in length(x)) {
if (abs(x[i]) <= 0.4) {
x[i] = ""
}
return(x)
}
}
a = c(5,4,-0.005)
remove_below_zerofour(a)
df = unclass(factor_model_fit$loadings)
remove_below_zerofour = function(x){
for (i in length(x)) {
if (abs(x[i]) <= 0.4) {
x[i] = ""
}
return(x)
}
}
apply(df, 1, remove_below_zerofour)
apply(df, 2, remove_below_zerofour)
df = unclass(factor_model_fit$loadings)
df = as.data.frame(unclass(factor_model_fit$loadings))
df
apply(df,1,max)
as.data.frame(apply(df,1,max))
df
remove_data = function(x){
for (i in length(x)) {
if (abs(x[i] <= 0.4)) {
a = ""
} else {
a = x[i]
}
}
return(x)
}
b = c(-0.03, 0.005,4,5)
remove_data(b)
remove_data = function(x){
for (i in length(x)) {
if (abs(x[i] <= 0.4)) {
a = ""
} else {
a = x[i]
}
}
return(a)
}
b = c(-0.03, 0.005,4,5)
remove_data(b)
remove_data = function(x){
for (i in length(x)) {
if (abs(x[i] <= 0.4)) {
x[i] = ""
} else {
x[i] = x[i]
}
}
return(x)
}
b = c(-0.03, 0.005,4,5)
remove_data(b)
remove_data = function(x){
for (i in length(x)) {
if (abs(x[i] <= 0.4)) {
x[i] = ""
} else {
x[i] = x[i]
}
return(x)
}
}
b = c(-0.03, 0.005,4,5)
remove_data(b)
remove_data = function(x){
for (i in length(x)) {
if (abs(x[i]) <= 0.4) {
x[i] = ""
} else {
x[i] = x[i]
}
return(x)
}
}
b = c(-0.03, 0.005,4,5)
remove_data(b)
remove_data = function(x){
for (i in length(x)) {
if (abs(x[i]) <= 0.4) {
x[i] = ""
}
return(x)
}
}
b = c(-0.03, 0.005,4,5)
remove_data(b)
remove_data = function(x){
for (i in 1:length(x)) {
if (abs(x[i]) <= 0.4) {
x[i] = ""
}
return(x)
}
}
b = c(-0.03, 0.005,4,5)
remove_data(b)
remove_data = function(x){
for (i in 1:length(x)) {
if (abs(x[i]) <= 0.4) {
x[i] = ""
}
}
return(x)
}
b = c(-0.03, 0.005,4,5)
remove_data(b)
remove_data = function(x){
result = c()
for (i in 1:length(x)) {
if (abs(x[i]) <= 0.4) {
result[i] = ""
} else {
result[i] = x[i]
}
}
return(result)
}
b = c(-0.03, 0.005,4,5)
remove_data(b)
apply(df,1,remove_data)
as.data.frame(apply(df,1,remove_data))
as.data.frame(apply(df,2,remove_data))
print.psych(factor_model_fit,cut = 0.35, sort = TRUE)
as.data.frame(apply(df,2,remove_data))
remove_data = function(x){
result = c()
for (i in 1:length(x)) {
if (abs(x[i]) <= 0.0.35) {
remove_data = function(x){
result = c()
for (i in 1:length(x)) {
if (abs(x[i]) <= 0.35) {
result[i] = ""
} else {
result[i] = x[i]
}
}
return(result)
}
as.data.frame(apply(df,2,remove_data))
remove_data = function(x){
result = c()
for (i in 1:length(x)) {
if (abs(x[i]) <= 0.35) {
result[i] = ""
} else {
result[i] = round(x[i],2)
}
}
return(result)
}
as.data.frame(apply(df,2,remove_data))
print.psych(factor_model_fit,cut = 0.35, sort = TRUE)
factor_loadings_df = as.data.frame(apply(df,2,remove_data))
View(factor_loadings_df)
E = paste0("E",c(1,10))
E = paste0("E",c(1,10))
N = paste0("N",c(1,10))
A = paste0("A",c(1,10))
C = paste0("C",c(1,10))
O = paste0("O",c(1,10))
names(factor_loadings_df)
row.names(E,N,A,C,O) = row.names(factor_loadings_df)
row.names(factor_loadings_df)=row.names(c(E,N,A,C,O))
View(factor_loadings_df)
E
factor_loadings_df = as.data.frame(apply(df,2,remove_data))
E = paste0("E",1:10)
N = paste0("N",1:10)
A = paste0("A",1:10)
C = paste0("C",1:10)
O = paste0("O",1:10)
row.names(factor_loadings_df)=row.names(c(E,N,A,C,O))
View(factor_loadings_df)
E
factor_loadings_df
factor_loadings_df = as.data.frame(apply(df,2,remove_data))
E = paste0("E",1:10)
N = paste0("N",1:10)
A = paste0("A",1:10)
C = paste0("C",1:10)
O = paste0("O",1:10)
row.names(factor_loadings_df)=c(E,N,A,C,O)
print.psych(factor_model_fit,cut = 0.35, sort = TRUE)
write.csv(factor_loadings_df, file = "C:/Users/admin/factor_analysis/BIG5/BIG5", row.names = TRUE)
write.csv(factor_loadings_df, file = "C:/Users/admin", row.names = TRUE)
file_path <- "C:/Users/admin/factor_loadings.csv"
write.csv(factor_loadings_df, file = file_path, row.names = TRUE)
# Step 3 : Estimate Models Parameters
factor_model_fit = principal(question_data,nfactors = 5,rotate = "varimax",scores=TRUE)
print.psych(factor_model_fit,cut = 0.35, sort = TRUE)
com_names = names(factor_model_fit$communality)
val = unname(factor_model_fit$communality)
communalities = cbind(com_names,val)
communalities
val = round(unname(factor_model_fit$communality),2)
communalities = cbind(com_names,val)
communalities
